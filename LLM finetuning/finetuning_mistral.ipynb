{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wothmag07/genai-bootcamp/blob/main/finetuning_mistral.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing the necessary libraries\n",
        "(https://huggingface.co/docs/transformers/quantization)"
      ],
      "metadata": {
        "id": "ezA7ncc3f-N9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWIf8aiIi6hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf79809-99c1-4039-d682-654b4f6a9038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Requirement already satisfied: auto-gptq in /usr/local/lib/python3.11/dist-packages (0.7.1)\n",
            "Requirement already satisfied: optim in /usr/local/lib/python3.11/dist-packages (0.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: py7zr in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.33.0)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl) (3.6.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from auto-gptq) (0.2.0)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.11/dist-packages (from auto-gptq) (1.0.1)\n",
            "Requirement already satisfied: gekko in /usr/local/lib/python3.11/dist-packages (from auto-gptq) (1.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: texttable in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.7.0)\n",
            "Requirement already satisfied: pycryptodomex>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (3.23.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.1.0)\n",
            "Requirement already satisfied: pyzstd>=0.16.1 in /usr/local/lib/python3.11/dist-packages (from py7zr) (0.17.0)\n",
            "Requirement already satisfied: pyppmd<1.3.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.2.0)\n",
            "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.0.6)\n",
            "Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from py7zr) (0.2.3)\n",
            "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.0.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from rouge->auto-gptq) (1.17.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.11.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install peft accelerate trl bitsandbytes auto-gptq optim transformers py7zr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "EdCvhB3Vu6n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "import torch, os\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, GPTQConfig\n",
        "from peft import LoraConfig, AutoPeftModelForCausalLM, prepare_model_for_kbit_training, get_peft_model\n",
        "from trl import SFTTrainer\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332,
          "referenced_widgets": [
            "df29dd9c2c0a4a2e83ed9ec3248890a2",
            "de2e81da92b74f1b9814ee667decb5b7",
            "3bcc170041d24cde88ee33ddb19e4b11",
            "b363480dbb414bb68b154d9ca4ea30d5",
            "cab644f17cf344db80bcf90768858c96",
            "a8b52b22ce9f4f31a0db7afea42e89f1",
            "85203e546efe487897094adf73d61845",
            "44527616dd3b4fbab91e3d306cd9272c",
            "05639aba33844b95856cb5ca67a52852",
            "0a7cf83208ec49abbc84c4181ae0d161",
            "a34907539bbd420584c39771ab1b085b",
            "97ebe560c97d4f3ca3cc8774e1f6e887",
            "0a0e4e3dc96d41bb940ae8dbf1ce1a86",
            "d0b7043d7d554dd88a42ede25be8053f",
            "e79a53da1468448c860f7b9137b6b75b",
            "8b6f2d99bca34c5190c3d5b2636aa617",
            "37a0ad937c4f4399a9271563ae208fb5"
          ]
        },
        "id": "d2RxwHNZgGmf",
        "outputId": "d5f3c7e6-a8ca-44d9-e7be-f81883357e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df29dd9c2c0a4a2e83ed9ec3248890a2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Samsum dataset (Dialogue summarization)"
      ],
      "metadata": {
        "id": "0N8odETOuuz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"knkarthick/samsum\", split=\"train\")\n",
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI-AtQ05sXCc",
        "outputId": "f597365e-62a7-4c44-ba53-2d385d1993a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'dialogue', 'summary'],\n",
              "    num_rows: 14732\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dsdf = ds.to_pandas()\n",
        "dsdf.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tavy4HfVv3XY",
        "outputId": "fc82470d-c560-4f38-9ef7-149421c6efd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                                           dialogue  \\\n",
              "0  13818513  Amanda: I baked  cookies. Do you want some?\\nJ...   \n",
              "1  13728867  Olivia: Who are you voting for in this electio...   \n",
              "2  13681000  Tim: Hi, what's up?\\nKim: Bad mood tbh, I was ...   \n",
              "3  13730747  Edward: Rachel, I think I'm in ove with Bella....   \n",
              "4  13728094  Sam: hey  overheard rick say something\\nSam: i...   \n",
              "\n",
              "                                             summary  \n",
              "0  Amanda baked cookies and will bring Jerry some...  \n",
              "1  Olivia and Olivier are voting for liberals in ...  \n",
              "2  Kim may try the pomodoro technique recommended...  \n",
              "3  Edward thinks he is in love with Bella. Rachel...  \n",
              "4  Sam is confused, because he overheard Rick com...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d06787c-e33c-44ca-be03-a9c1f70e7341\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dialogue</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13818513</td>\n",
              "      <td>Amanda: I baked  cookies. Do you want some?\\nJ...</td>\n",
              "      <td>Amanda baked cookies and will bring Jerry some...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13728867</td>\n",
              "      <td>Olivia: Who are you voting for in this electio...</td>\n",
              "      <td>Olivia and Olivier are voting for liberals in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13681000</td>\n",
              "      <td>Tim: Hi, what's up?\\nKim: Bad mood tbh, I was ...</td>\n",
              "      <td>Kim may try the pomodoro technique recommended...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13730747</td>\n",
              "      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n",
              "      <td>Edward thinks he is in love with Bella. Rachel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13728094</td>\n",
              "      <td>Sam: hey  overheard rick say something\\nSam: i...</td>\n",
              "      <td>Sam is confused, because he overheard Rick com...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d06787c-e33c-44ca-be03-a9c1f70e7341')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9d06787c-e33c-44ca-be03-a9c1f70e7341 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9d06787c-e33c-44ca-be03-a9c1f70e7341');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a8b5c3b2-7969-4f7b-80bd-7e227937c78e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a8b5c3b2-7969-4f7b-80bd-7e227937c78e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a8b5c3b2-7969-4f7b-80bd-7e227937c78e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dsdf",
              "summary": "{\n  \"name\": \"dsdf\",\n  \"rows\": 14732,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14732,\n        \"samples\": [\n          \"13811908\",\n          \"13716431\",\n          \"13810214\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dialogue\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14255,\n        \"samples\": [\n          \"Matt: How are you doing babe?\\nOla: Just got called to the doctor's office. Talk to you later!\\nMatt: Good luck!\",\n          \"Julia: Will you be coming for the graduation?\\nCecilie: Sure! You?\\nJulia: Me too, I just bought my flight tickets. \",\n          \"Annabell: I burnt  my skin a bit\\nAnnabell: Lower parts of my legs lol\\nValentin: U got some color?\\nAnnabell: I got red in that place and it hurts\\nAnnabell: <file_photo>\\nValentin: U have to put some cream\\nAnnabell: I will do it when i get home\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14730,\n        \"samples\": [\n          \"Violet sent Claire Austin's article.\",\n          \"Michael, Tom and Chris tease Mark because he has a new girlfriend.\",\n          \"Leo just had a very good time with his parents in Spain. Granny will be happy if he came round and told her about his holidays. He could also see flowers blooming in her and Daddy's garden.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dsdf[\"text\"] = dsdf.apply(lambda row: f\"###Human: Summarize this following dialogue: {row['dialogue']}\\n###Assistant: {row['summary']}\", axis=1)\n",
        "dsdf.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "ddSCcjkw6lXH",
        "outputId": "dbbb6972-7e62-4822-cba0-4c4e68d9c99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                                                   13818513\n",
              "dialogue    Amanda: I baked  cookies. Do you want some?\\nJ...\n",
              "summary     Amanda baked cookies and will bring Jerry some...\n",
              "text        ###Human: Summarize this following dialogue: A...\n",
              "Name: 0, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>13818513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dialogue</th>\n",
              "      <td>Amanda: I baked  cookies. Do you want some?\\nJ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>summary</th>\n",
              "      <td>Amanda baked cookies and will bring Jerry some...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>###Human: Summarize this following dialogue: A...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing tokenizer, model with quantization config"
      ],
      "metadata": {
        "id": "X57buGiUu_Wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "quant_conf = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                                bnb_4bit_quant_type=\"nf4\",\n",
        "                                bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "                                bnb_4bit_use_double_quant=True\n",
        "                                )\n",
        "# quant_conf = GPTQConfig(bits=4, disable_exllama=True, tokenizer=tokenizer)\n",
        "# model_id = \"TheBloke/Mistral-7B-Instruct-v0.1-GPTQ\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
        "                                             device_map=\"auto\",\n",
        "                                             trust_remote_code=True,\n",
        "                                             quantization_config=quant_conf)\n"
      ],
      "metadata": {
        "id": "YkkN7ce29Gg3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e60915d9a4734ca38efe78a6b9149535",
            "181a617c2c60470fbe751b1ef1c7c820",
            "989547cee7b04e12af56f8f99dc796c9",
            "f6526aacea644429ae15fdb36a4281b7",
            "7f4123bba97147ba89dcc69d23c0da47",
            "08493ef35f664c5d8220ebdf191c329e",
            "123db7a69e5840949236f07d5c02eb62",
            "5caeb609b0ad4d08b275dc2d379d3409",
            "bc63aed73a554a91b4116151f8562570",
            "7b2e7ac674164656b285c39d0c3c031a",
            "08a911b10571483da290398eacb43e0c"
          ]
        },
        "outputId": "623f1f21-7c79-441a-d9f2-2a21ed238617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e60915d9a4734ca38efe78a6b9149535"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.use_cache=False\n",
        "model.config.pretraining_tp=1\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "meY7c9k_2JyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "PbTxbaCrDiGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28107fcf-c548-4105-b6ac-a0600f22564d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MistralForCausalLM(\n",
            "  (model): MistralModel(\n",
            "    (embed_tokens): Embedding(32768, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x MistralDecoderLayer(\n",
            "        (self_attn): MistralAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "        )\n",
            "        (mlp): MistralMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
            "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
            "    (rotary_emb): MistralRotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.eos_token, tokenizer.eos_token_id, tokenizer.pad_token, tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64eRB8KBr2d2",
        "outputId": "7088a6f6-8334-417a-d16d-41ac2fcfdcf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('</s>', 2, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "CjrSIOb_7iuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LORA configurations"
      ],
      "metadata": {
        "id": "qkYPQeQquq3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(r=16,\n",
        "                         lora_alpha=32,\n",
        "                         task_type=\"CAUSAL_LM\",\n",
        "                         bias=\"none\",\n",
        "                         target_modules=[\"q_proj\", \"v_proj\"],\n",
        "                         lora_dropout=0.05)\n",
        "\n",
        "qmodel = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "id": "JK-LUpMesNt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(qmodel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyQTg4USzts6",
        "outputId": "f049fad3-4050-4138-ceae-927ec2c1000f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): MistralForCausalLM(\n",
            "      (model): MistralModel(\n",
            "        (embed_tokens): Embedding(32768, 4096)\n",
            "        (layers): ModuleList(\n",
            "          (0-31): 32 x MistralDecoderLayer(\n",
            "            (self_attn): MistralAttention(\n",
            "              (q_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "              (v_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "            )\n",
            "            (mlp): MistralMLP(\n",
            "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "              (act_fn): SiLU()\n",
            "            )\n",
            "            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
            "            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
            "        (rotary_emb): MistralRotaryEmbedding()\n",
            "      )\n",
            "      (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training pipeline"
      ],
      "metadata": {
        "id": "5HX0aUJX7Vxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(output_dir=\"mistral-finetuned-samsum\",\n",
        "                                  per_device_train_batch_size=8,\n",
        "                                  gradient_accumulation_steps=1,\n",
        "                                  optim=\"paged_adamw_32bit\",\n",
        "                                  learning_rate=2e-4,\n",
        "                                  lr_scheduler_type=\"cosine\",\n",
        "                                  save_strategy=\"epoch\",\n",
        "                                  logging_steps=100,\n",
        "                                  num_train_epochs=1,\n",
        "                                  max_steps=250,\n",
        "                                  fp16=True,\n",
        "                                  push_to_hub=True,\n",
        "                                  report_to=\"none\")\n",
        "trainer = SFTTrainer(model=qmodel,\n",
        "                     train_dataset=Dataset.from_pandas(dsdf),\n",
        "                     peft_config=peft_config,\n",
        "                     args=training_args)\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345,
          "referenced_widgets": [
            "200d4fa170c047eb87169014e2b16df7",
            "663ef27daa7145dc96f461a2c6eb8f38",
            "fa5a4822c8f54dac9a9a7379572a4c02",
            "bbdddfc3835741499fbccadab34e0145",
            "c88f59e7572b47e7b828d00b5a253b03",
            "95b17c41ced04ba8a4a7d340eb68c4cb",
            "bb01421b06e7474c90c0b0135d40b4bd",
            "19b49bfc7f0c44c2a50674a1e453a48e",
            "8d4e87bd90884512a1f0bf8899594fc3",
            "ff235e799edf4fae97184d96cc9e7fc0",
            "f37a0fb41b844104991c84ee95a76ec2",
            "11def404ef4141198fee5d8e143c25b0",
            "29852ab329734bfea9098afb45c9c6b5",
            "9e39291ace104ea6aa899679152115ce",
            "5065445c109943758ecd45e4b79ebbbf",
            "41b17ed7a29147d9af4a2955ad9f4acf",
            "0c5f6e9fd6334df493f7e87d53088fcf",
            "90d2986d41c646228e90dbd67c61b4e2",
            "79378e4bd2bb4c39ab40dadb02060ec4",
            "02646ca075cc45cea5674e1b009a7ab4",
            "616a467809f04e31b96ae2de36f05659",
            "8333a4d30684480b97a58385ca80ec29",
            "8a552a40eb3f405d8e9be358540f725b",
            "be1e0df99150499da455d0c4e715af3d",
            "254aa9c9f6a647d1831060fc14ea4ecd",
            "e37c524835744cb58e918b07031f0045",
            "a267d11059ea4a27988b8776b27a22d1",
            "db414b98ce1c41769a2e0f55379e3367",
            "a5af300ca6df4b83af103a68e6f9f4f0",
            "d967d0c50e96455c832c6aa73db0de76",
            "bc258f9a6e44475d9b153e34680c6481",
            "8de787c334b04d49a4d1f5571712ed56",
            "afc4eb44f62c487c88cc7685e40efab7"
          ]
        },
        "id": "pM6pZG8Ozvhu",
        "outputId": "5485a675-2d59-4092-f09a-2fc9f3f045e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding EOS to train dataset:   0%|          | 0/14732 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "200d4fa170c047eb87169014e2b16df7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/14732 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11def404ef4141198fee5d8e143c25b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/14732 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a552a40eb3f405d8e9be358540f725b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 44:54, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.800600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.715600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=250, training_loss=1.7462933959960938, metrics={'train_runtime': 2710.1384, 'train_samples_per_second': 0.738, 'train_steps_per_second': 0.092, 'total_flos': 3.540327471631565e+16, 'train_loss': 1.7462933959960938})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference mode"
      ],
      "metadata": {
        "id": "k8vlSXrdJkPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWDgKGVoZh57",
        "outputId": "a79395c0-af28-410c-bf44-425d242c3a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/mistral-finetuned-samsum/ /content/drive/MyDrive/models/"
      ],
      "metadata": {
        "id": "narl4nqmZcL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import AutoPeftModelForCausalLM\n",
        "from transformers import GenerationConfig\n",
        "from transformers import AutoTokenizer\n",
        "import torch"
      ],
      "metadata": {
        "id": "elQsenuoaRgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/models/mistral-finetuned-samsum\")\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/models/mistral-finetuned-samsum\",\n",
        "                                                  low_cpu_mem_usage=True,\n",
        "                                                  return_dict=True,\n",
        "                                                  torch_dtype=torch.bfloat16,\n",
        "                                                  device_map=\"cuda\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366,
          "referenced_widgets": [
            "a28f9c98a714438c863e123f64a35f77",
            "b3ff9673520e4584a6057c13e64ac318",
            "dcefa190a5c14d8aaa5b23fb7dcf3292",
            "5c234ae01bdc4cfeb69adf34bce4f248",
            "7be128562a4648dd8241934d0226931c",
            "cb611c0c60f14d138f353b1fa95f1531",
            "032748b5dd6447a78ff17482c260fd3e",
            "1e1095ff311b4e9a9c36aba73dd282ee",
            "f73ad07535034623901141c8d8752233",
            "b3c0d57d518944bc93b8a421bf37f674",
            "f2fb8bc5c67e40a986399096f8edc585",
            "a6ffc817998148e799ad9b06a860fbf6",
            "7b72d28ab0c54b1a8e8d8337939ba87b",
            "3fb4a55d800b414ab2fb36c4c6c21645",
            "ae7d4f5acc8a40ffbbf79375bde21031",
            "ca6eda406d8347a9abc7da520fbd6c39",
            "96638f6c824d43cf883f05438ad3fca4",
            "c71efc9f5ba2488db680f5a1cafe8ffe",
            "e538ae59ebf1442795d995d5014c2723",
            "99e1c78f914d48ed85fa13716e0c583b",
            "53fc3e597f1549eca44ab62853c12c1e",
            "6ca5e15ebd4145c4a8f2e6867d989fa6",
            "aa65b58b8bb7455d80c34fa1409ae5a2",
            "0e8a1569c2b84720b75c2ffb11bad1d8",
            "688734487b1c42469bad172e4f82c2f3",
            "328c52edc7d94ea9a891dfe21a570de7",
            "b513e92905b4429d828cdb308bf7aab6",
            "782de3f5052a453aa824d3c8313ecd01",
            "e4e1415dc53c4b36b7b6efce237c1067",
            "47b2c3e6b64c4543894a4c653edc1dc0",
            "51d905d801854c0098623368d538e007",
            "06ac3c8f1fce4069be0f1921c79c9514",
            "293e32a4bdeb4228aeb38195639e192e",
            "9c3db1a927c54202bcb53a1f872c7f0a",
            "6be345a6fa9c4003aa198b823b195665",
            "4a14815475a549aebd2eac3bd673f8c6",
            "972d5dfae42a46b48c11f545ca9d2518",
            "6e08d912790949618dce1ffa8caf44bc",
            "a55bc17201284452bdb6df2c9389fd27",
            "c84eafc702f247f69f321fb59cae5c57",
            "4fd1891443eb43fb8f69f4acacc081b2",
            "26a09d2c73bc452d85c3e5f00dc124e3",
            "cb89a7be2c324609903b7347468b7a0a",
            "8c50598f8c264aa88c03a00d1be92f2a",
            "b38d7e7a71b74510be9ee5cbd29549eb",
            "85adf985de4b4d6aa388788183d54d3b",
            "3a3d18c033a641e189efd5ed3b01bc8f",
            "390cdeda53b44a749367a909d114fc32",
            "570272121c7a40c28e936eb67fbe8ee6",
            "a1e573d84bdc42cbaae8dfc6199980e9",
            "8eb2f79691444edf85bdfad2f3ad75c1",
            "58ce18155b7c4a88900c42da11ee0fb0",
            "243672a5531e42cfa911796491ce3c4d",
            "f46030e36e2642e6ba0c6b2bdd8c60df",
            "63500348e2b14c7e98c892cf05f529d2",
            "20ac29a806654c20964af23848e69a3e",
            "2e48be06f87c4736818dfb064f38aef3",
            "22db977f8a5748eb80af56d554883bd0",
            "19335a7198114a31b13680dabfc50a28",
            "5523420003004fee90e0c30d7d66744b",
            "541ffe68e4e949d8b0369d283e36a46e",
            "55519faa143643ceb8b50c0b42fec340",
            "f4cec4f6e5044f0ea14346218c6e845c",
            "c874b7c77f1940dca23a78dcb25e9d40",
            "f68089a171ff41b1a020b22d32f5ebbe",
            "4f345c5c9589461891b7dd85a9acb583",
            "06ab2adb56024bf88907d46167f6b003",
            "ffd6bb8d777d4939aad2229a882caf0c",
            "107bed000a764e3182ef7b9e22bb250e",
            "2f88242cc8d04db2933d5a75d92a9ff6",
            "0d803adbc0c4408cb54d465fe7a050a9",
            "f1a023902c9943d08ee4e319f60e19d4",
            "cfc153f054e646d8a55281312fbb27e4",
            "9939ea897fbe4c4383066b30d8084c79",
            "0287853c4c094d4babaf597cce0d561d",
            "70bbf08e54da4ce8be435203bbc56b0d",
            "53df46086e3c4bdc8f5ad42662a5ce65",
            "74ded92074d84a2ea88f415ba9a8556f",
            "5b15115a8d944125a71fc74ac042ec7c",
            "b4c166debfe549e48f022a6180028919",
            "00ee703623a84f338bc947c6a49f44f1",
            "4d12d065b2b64bcf94eb04ff81a8b7db",
            "2ef3f5c9d39b481f8a160f1092f97c8f",
            "3d0d280c2ca94dc9ab6393466a0b5061",
            "523fa55bce59481097ee51ad4902c490",
            "27deca5e7a374178bedb62c31c0b6d6b",
            "68f07d1ddff9445fb2338252f1722cda",
            "6cee613381eb4a83a220e78e908932e5"
          ]
        },
        "id": "TWThJJYyJloQ",
        "outputId": "b928a818-62ac-4b15-f156-1a424e991925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/config.py:162: UserWarning: Unexpected keyword arguments ['alpha_pattern', 'bias', 'corda_config', 'eva_config', 'exclude_modules', 'fan_in_fan_out', 'init_lora_weights', 'layer_replication', 'layers_pattern', 'layers_to_transform', 'loftq_config', 'lora_alpha', 'lora_bias', 'lora_dropout', 'megatron_config', 'megatron_core', 'modules_to_save', 'r', 'rank_pattern', 'target_modules', 'trainable_token_indices', 'use_dora', 'use_rslora'] for class PeftConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a28f9c98a714438c863e123f64a35f77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6ffc817998148e799ad9b06a860fbf6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa65b58b8bb7455d80c34fa1409ae5a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c3db1a927c54202bcb53a1f872c7f0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b38d7e7a71b74510be9ee5cbd29549eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20ac29a806654c20964af23848e69a3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06ab2adb56024bf88907d46167f6b003"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74ded92074d84a2ea88f415ba9a8556f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/config.py:162: UserWarning: Unexpected keyword arguments ['corda_config', 'trainable_token_indices'] for class LoraConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialogue = \"\"\"\n",
        "Alex: Hey, are you free this weekend?\n",
        "Sarah: Yeah, what's up?\n",
        "Alex: Want to go to that new restaurant downtown?\n",
        "Sarah: The Italian one? I heard it's really good!\n",
        "Alex: That's the one. How about Saturday around 7?\n",
        "Sarah: Perfect! Should I make a reservation?\n",
        "Alex: Good idea, I'll call them now.\n",
        "\"\"\"\n",
        "\n",
        "test_prompt = f\"\"\"\n",
        "###Human: Summarize this following dialogue: {dialogue}\n",
        "###Assistant: \"\"\"\n",
        "\n",
        "inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "inputs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGlkMvHGQlBx",
        "outputId": "95da60d8-fe8c-4bd2-bbcc-adad8cb2f7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    1, 29473,   781, 28100, 29537,  7134, 29515,  7695,  4247,  1421,\n",
              "          1224,  3064, 19966, 29515, 29473,   781, 26957, 29515, 17930, 29493,\n",
              "          1228,  1136,  2701,  1224,  9839, 29572,   781, 29503,  1051,  1680,\n",
              "         29515,  9120, 29493,  1535, 29510, 29481,  1350, 29572,   781, 26957,\n",
              "         29515, 19986,  1066,  1344,  1066,  1137,  1401, 10694, 19298, 29572,\n",
              "           781, 29503,  1051,  1680, 29515,  1183, 10856,  1392, 29572,  1083,\n",
              "          4132,  1146, 29510, 29481,  2296,  1947, 29576,   781, 26957, 29515,\n",
              "          2493, 29510, 29481,  1040,  1392, 29491,  2370,  1452,  9281,  2169,\n",
              "         29473, 29555, 29572,   781, 29503,  1051,  1680, 29515, 25211, 29576,\n",
              "         11702,  1083,  1806,  1032,  6815,  1120, 29572,   781, 26957, 29515,\n",
              "          6569,  3796, 29493,  1083, 29510,  1352,  1802,  1474,  1823, 29491,\n",
              "           781,   781, 28100,  7994, 11911, 29515, 29473]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
              "       device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.generate(**inputs, do_sample=True, top_p=0.9, temperature=0.8, max_new_tokens=150)\n",
        "tokenizer.decode(output[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "NqQDRDPebeRz",
        "outputId": "d5c4736e-2d92-46e9-fd07-885766e81bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n###Human: Summarize this following dialogue: \\nAlex: Hey, are you free this weekend?\\nSarah: Yeah, what's up?\\nAlex: Want to go to that new restaurant downtown?\\nSarah: The Italian one? I heard it's really good!\\nAlex: That's the one. How about Saturday around 7?\\nSarah: Perfect! Should I make a reservation?\\nAlex: Good idea, I'll call them now.\\n\\n###Assistant:  Sarah and Alex are going to an Italian restaurant on Saturday around 7.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example2"
      ],
      "metadata": {
        "id": "emxkl3zej1qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dialogue = \"\"\"\n",
        "Client: We're having issues with the software update.\n",
        "Support: I understand your concern. Can you describe the specific problem?\n",
        "Client: The new interface is confusing our employees.\n",
        "Support: We can provide additional training sessions for your team.\n",
        "Client: That would be helpful. When can we schedule this?\n",
        "Support: How about next Tuesday at 2 PM?\n",
        "Client: That works perfectly. Thank you for the quick response.\n",
        "\"\"\"\n",
        "test_prompt = f\"\"\"\n",
        "###Human: Summarize this following dialogue: {dialogue}\n",
        "###Assistant: \"\"\"\n",
        "\n",
        "input2 = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "input2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXIRkEvcecqV",
        "outputId": "4ad1f21a-f08b-40b7-ccf9-91330bb81f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    1, 29473,   781, 28100, 29537,  7134, 29515,  7695,  4247,  1421,\n",
              "          1224,  3064, 19966, 29515, 29473,   781,  3934, 29515,  1584, 29510,\n",
              "          1035,  3229,  5150,  1163,  1040,  4698,  4777, 29491,   781, 10220,\n",
              "         29515,  1083,  3148,  1342,  5136, 29491,  3186,  1136,  7453,  1040,\n",
              "          3716,  3468, 29572,   781,  3934, 29515,  1183,  1401,  5739,  1117,\n",
              "         27512,  1581,  8664, 29491,   781, 10220, 29515,  1584,  1309,  3852,\n",
              "          5638,  4922, 14680,  1122,  1342,  2686, 29491,   781,  3934, 29515,\n",
              "          2493,  1450,  1115, 11633, 29491,  2452,  1309,  1246, 10210,  1224,\n",
              "         29572,   781, 10220, 29515,  2370,  1452,  2447, 11955,  1206, 29473,\n",
              "         29518, 10400, 29572,   781,  3934, 29515,  2493,  4559, 10711, 29491,\n",
              "          8580,  1136,  1122,  1040,  3704,  3667, 29491,   781,   781, 28100,\n",
              "          7994, 11911, 29515, 29473]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
              "       device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output2 = model.generate(**input2, do_sample=True, top_p=0.9, temperature=0.8, max_new_tokens=150)\n",
        "tokenizer.decode(output2[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "-If1iuN0j88O",
        "outputId": "5618ab7f-ee91-433b-854b-27a27f382837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n###Human: Summarize this following dialogue: \\nClient: We're having issues with the software update.\\nSupport: I understand your concern. Can you describe the specific problem?\\nClient: The new interface is confusing our employees.\\nSupport: We can provide additional training sessions for your team.\\nClient: That would be helpful. When can we schedule this?\\nSupport: How about next Tuesday at 2 PM?\\nClient: That works perfectly. Thank you for the quick response.\\n\\n###Assistant: \\nThe client has problems with the new software update. The interface is confusing their employees. They need additional training sessions. Support will offer them a training session on next Tuesday at 2 PM.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "weoG-h_qkKT3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}